{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>aback</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>abacus</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>abandon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>abandoned</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14177</td>\n",
       "      <td>zone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14178</td>\n",
       "      <td>zoo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14179</td>\n",
       "      <td>zoological</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14180</td>\n",
       "      <td>zoology</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14181</td>\n",
       "      <td>zoom</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14182 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion        word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "0               NaN      0             0        0     0    0         0   \n",
       "1             aback      0             0        0     0    0         0   \n",
       "2            abacus      0             0        0     0    0         0   \n",
       "3           abandon      0             0        0     1    0         1   \n",
       "4         abandoned      1             0        0     1    0         1   \n",
       "...             ...    ...           ...      ...   ...  ...       ...   \n",
       "14177          zone      0             0        0     0    0         0   \n",
       "14178           zoo      0             0        0     0    0         0   \n",
       "14179    zoological      0             0        0     0    0         0   \n",
       "14180       zoology      0             0        0     0    0         0   \n",
       "14181          zoom      0             0        0     0    0         0   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "0               0        0         0      0  \n",
       "1               0        0         0      0  \n",
       "2               0        0         0      1  \n",
       "3               0        1         0      0  \n",
       "4               0        1         0      0  \n",
       "...           ...      ...       ...    ...  \n",
       "14177           0        0         0      0  \n",
       "14178           0        0         0      0  \n",
       "14179           0        0         0      0  \n",
       "14180           0        0         0      0  \n",
       "14181           0        0         0      0  \n",
       "\n",
       "[14182 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "emolex_df = pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], sep='\\t')\n",
    "emolex_words = emolex_df.pivot(index='word',columns='emotion',values='association').reset_index()\n",
    "emolex_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337337, 5)\n"
     ]
    }
   ],
   "source": [
    "df_merge = pd.read_csv('full_merge.csv')\n",
    "df_merge = df_merge.dropna()\n",
    "df_merge.head()\n",
    "print(df_merge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337337, 9)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drugs_grouped = df_merge.groupby('Drug').count()\n",
    "# drug_review_grouping = drugs_grouped.merge(df_merge,on='Drug',how='inner')\n",
    "# df_new = drug_review_grouping.drop_duplicates()\n",
    "# df_new.shape\n",
    "#df_new.to_csv('df_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"my son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>drugs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"the actavis generic version of this medicatio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>drugs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"my son was just diagnosed adhd today. he's 5 ...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>drugs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"the first few days on 1 mg in the morning, he...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>drugs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>guanfacine</td>\n",
       "      <td>adhd</td>\n",
       "      <td>\"ours 8 year old son as done so much better wi...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>drugs.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337348</td>\n",
       "      <td>isoniazid</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>i am having some of these side effects and wil...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>webmd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337349</td>\n",
       "      <td>isoniazid</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>made me tired,achy,and was told not to take st...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>webmd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337350</td>\n",
       "      <td>isoniazid</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>it makes me feel like crap after i take it.\\ni...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>webmd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337351</td>\n",
       "      <td>isoniazid</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>when i strated taking the medication i was fin...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>webmd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337352</td>\n",
       "      <td>rifadin</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>due to all the medication i'm was unable to co...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>webmd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>337337 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Drug     Condition  \\\n",
       "0       guanfacine          adhd   \n",
       "1       guanfacine          adhd   \n",
       "2       guanfacine          adhd   \n",
       "3       guanfacine          adhd   \n",
       "4       guanfacine          adhd   \n",
       "...            ...           ...   \n",
       "337348   isoniazid  tuberculosis   \n",
       "337349   isoniazid  tuberculosis   \n",
       "337350   isoniazid  tuberculosis   \n",
       "337351   isoniazid  tuberculosis   \n",
       "337352     rifadin  tuberculosis   \n",
       "\n",
       "                                                  Reviews  Rating    Website  \n",
       "0       \"my son is halfway through his fourth week of ...     8.0  drugs.com  \n",
       "1       \"the actavis generic version of this medicatio...     1.0  drugs.com  \n",
       "2       \"my son was just diagnosed adhd today. he's 5 ...     7.0  drugs.com  \n",
       "3       \"the first few days on 1 mg in the morning, he...     4.0  drugs.com  \n",
       "4       \"ours 8 year old son as done so much better wi...    10.0  drugs.com  \n",
       "...                                                   ...     ...        ...  \n",
       "337348  i am having some of these side effects and wil...     2.0      webmd  \n",
       "337349  made me tired,achy,and was told not to take st...     2.0      webmd  \n",
       "337350  it makes me feel like crap after i take it.\\ni...     3.0      webmd  \n",
       "337351  when i strated taking the medication i was fin...     2.0      webmd  \n",
       "337352  due to all the medication i'm was unable to co...     3.0      webmd  \n",
       "\n",
       "[337337 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_drug_reviews_merged = df_new[['Drug','Reviews_y']].rename(columns={'Reviews_y':'Reviews'})\n",
    "df_merge['Reviews'] = df_merge['Reviews'].str.replace(\"&#039;\",'\\'')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_review_emotion(df,column):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    filepath = \"NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-v0.92/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "    emolex_df = pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], sep='\\t')\n",
    "    emolex_words = emolex_df.pivot(index='word',columns='emotion',values='association').reset_index()\n",
    "    \n",
    "    emotions = emolex_words.columns.drop('word')\n",
    "    emo_df = pd.DataFrame(0, index=df.index, columns=emotions)\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    with tqdm(total=len(list(new_df.iterrows()))) as pbar:\n",
    "        for i, row in new_df.iterrows():\n",
    "            pbar.update(1)\n",
    "            document = word_tokenize(new_df.loc[i][column])\n",
    "            for word in document:\n",
    "                word = stemmer.stem(word.lower())\n",
    "                emo_score = emolex_words[emolex_words.word == word]\n",
    "                if not emo_score.empty:\n",
    "                    for emotion in list(emotions):\n",
    "                        emo_df.at[i, emotion] += emo_score[emotion]\n",
    "\n",
    "    new_df = pd.concat([new_df, emo_df], axis=1)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = extract_review_emotion(df_merge, 'Reviews')\n",
    "emotion_df.to_csv('emotion_sentiment.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Website</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>232363</td>\n",
       "      <td>adderall</td>\n",
       "      <td>adhd</td>\n",
       "      <td>add with mild ocd as well. the med is very eff...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>webmd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188173</td>\n",
       "      <td>generess fe</td>\n",
       "      <td>birth control</td>\n",
       "      <td>after reading everyone's horrifying posts i wa...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>webmd</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14335</td>\n",
       "      <td>etonogestrel</td>\n",
       "      <td>birth control</td>\n",
       "      <td>\"i had the implanon after i had my son. i was ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>drugs.com</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198901</td>\n",
       "      <td>benzonatate</td>\n",
       "      <td>cough</td>\n",
       "      <td>i have taken the meds for one day and feeling ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>webmd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92841</td>\n",
       "      <td>mucinex d</td>\n",
       "      <td>cough and nasal congestion</td>\n",
       "      <td>\"twice this year i have had a cold and used th...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>drugs.com</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Drug                   Condition  \\\n",
       "232363      adderall                        adhd   \n",
       "188173   generess fe               birth control   \n",
       "14335   etonogestrel               birth control   \n",
       "198901   benzonatate                       cough   \n",
       "92841      mucinex d  cough and nasal congestion   \n",
       "\n",
       "                                                  Reviews  Rating    Website  \\\n",
       "232363  add with mild ocd as well. the med is very eff...     8.0      webmd   \n",
       "188173  after reading everyone's horrifying posts i wa...     9.0      webmd   \n",
       "14335   \"i had the implanon after i had my son. i was ...     2.0  drugs.com   \n",
       "198901  i have taken the meds for one day and feeling ...    10.0      webmd   \n",
       "92841   \"twice this year i have had a cold and used th...     8.0  drugs.com   \n",
       "\n",
       "        anger  anticipation  disgust  fear  joy  negative  positive  sadness  \\\n",
       "232363      1             0        1     1    0         3         1        1   \n",
       "188173      1             6        0     1    1         1         4        0   \n",
       "14335       0             0        0     0    0         0         0        0   \n",
       "198901      0             0        1     0    0         1         0        0   \n",
       "92841       1             2        0     1    0         2         3        0   \n",
       "\n",
       "        surprise  trust  \n",
       "232363         0      1  \n",
       "188173         3      3  \n",
       "14335          2      0  \n",
       "198901         0      0  \n",
       "92841          0      3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_emotions_df = pd.read_csv('emotion_sentiment.csv')\n",
    "rev_samp = read_emotions_df.sample(n=5,random_state = 42)\n",
    "rev_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
